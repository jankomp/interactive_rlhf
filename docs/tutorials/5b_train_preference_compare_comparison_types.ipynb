{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[download this notebook here](https://github.com/HumanCompatibleAI/imitation/blob/master/docs/tutorials/5_train_preference_comparisons.ipynb)\n",
    "# We want to compare pairwise comparison with groupwise comparison\n",
    "\n",
    "We will use synthetic feedback based on the true reward function of the reacher environment to evaluate and compare pairwise comparison and pairwise group comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the preference comparisons algorithm, we first need to set up a lot of its internals beforehand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from imitation.algorithms import preference_comparisons\n",
    "from imitation.rewards.reward_nets import BasicRewardNet, RewardEnsemble\n",
    "from imitation.util.networks import RunningNorm\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.policies.base import FeedForward32Policy, NormalizeFeaturesExtractor\n",
    "from imitation.regularization.regularizers import LpRegularizer\n",
    "from imitation.regularization.updaters import IntervalParamScaler\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np\n",
    "from imitation.util import logger\n",
    "import stable_baselines3.common.logger as sb_logger\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "def intantiate_and_train(pairwise, tb_log_name):\n",
    "    # make sure that max_episode_steps is divisible by fragment_length\n",
    "    max_episode_steps = 1000\n",
    "    fragment_length = 25\n",
    "    gravity = -9.81\n",
    "\n",
    "    venv = make_vec_env(\"Hopper-v4\", rng=rng, render_mode='rgb_array', n_envs=1, max_episode_steps=max_episode_steps, env_make_kwargs={'terminate_when_unhealthy': False}, gravity=gravity)\n",
    "\n",
    "    reward_net_members = [BasicRewardNet(venv.observation_space, venv.action_space, normalize_input_layer=RunningNorm) for _ in range(5)]\n",
    "    reward_net = RewardEnsemble(venv.observation_space, venv.action_space, reward_net_members)\n",
    "\n",
    "    preference_model = preference_comparisons.PreferenceModel(reward_net)\n",
    "    # reward_trainer = preference_comparisons.BasicRewardTrainer(\n",
    "    #     preference_model=preference_model,\n",
    "    #     loss=preference_comparisons.CrossEntropyRewardLoss(),\n",
    "    #     epochs=3,\n",
    "    #     rng=rng,\n",
    "    # )\n",
    "\n",
    "\n",
    "    # Create a lambda updater\n",
    "    scaling_factor = 0.1\n",
    "    tolerable_interval = (0.9, 1.1) \n",
    "    lambda_updater = IntervalParamScaler(scaling_factor, tolerable_interval)\n",
    "    # Create a RegularizerFactory\n",
    "    regularizer_factory = LpRegularizer.create(initial_lambda=0.1, lambda_updater=lambda_updater, p=2, val_split=0.1)\n",
    "\n",
    "    reward_trainer = preference_comparisons.EnsembleTrainer(\n",
    "        preference_model,\n",
    "        loss=preference_comparisons.CrossEntropyRewardLoss(),\n",
    "        rng=rng,\n",
    "        epochs=5,\n",
    "        batch_size = 4,\n",
    "        minibatch_size = 2,\n",
    "        # lr: float = 1e-3,\n",
    "        # custom_logger: Optional[imit_logger.HierarchicalLogger] = None,\n",
    "        regularizer_factory = regularizer_factory,\n",
    "    )\n",
    "    if pairwise:\n",
    "        base_fragmenter = preference_comparisons.RandomFragmenter(\n",
    "            warning_threshold=0,\n",
    "            rng=rng,\n",
    "        )\n",
    "        fragmenter = preference_comparisons.ActiveSelectionFragmenter(\n",
    "                preference_model,\n",
    "                base_fragmenter,\n",
    "                2.0,\n",
    "        )\n",
    "        gatherer = preference_comparisons.SyntheticGatherer(rng=rng)\n",
    "    else:\n",
    "        fragmenter = preference_comparisons.AbsoluteUncertaintyFragmenter(\n",
    "            preference_model,\n",
    "            2.0,\n",
    "            rng=rng,\n",
    "        )\n",
    "        gatherer = preference_comparisons.SyntheticGathererForGroupComparisons(rng=rng, augment_to_group_size=3)\n",
    "    # Several hyperparameters (reward_epochs, ppo_clip_range, ppo_ent_coef,\n",
    "    # ppo_gae_lambda, ppo_n_epochs, discount_factor, use_sde, sde_sample_freq,\n",
    "    # ppo_lr, exploration_frac, num_iterations, initial_comparison_frac,\n",
    "    # initial_epoch_multiplier, query_schedule) used in this example have been\n",
    "    # approximately fine-tuned to reach a reasonable level of performance.\n",
    "    agent = PPO(\n",
    "        policy=FeedForward32Policy,\n",
    "        policy_kwargs=dict(\n",
    "            features_extractor_class=NormalizeFeaturesExtractor,\n",
    "            features_extractor_kwargs=dict(normalize_class=RunningNorm),\n",
    "        ),\n",
    "        env=venv,\n",
    "        seed=0,\n",
    "        n_steps=2048 // venv.num_envs,\n",
    "        batch_size=64,\n",
    "        ent_coef=0.01,\n",
    "        learning_rate=2e-3,\n",
    "        clip_range=0.1,\n",
    "        gae_lambda=0.95,\n",
    "        gamma=0.97,\n",
    "        n_epochs=10,\n",
    "        tensorboard_log=\"./compare_feedback_types/\",\n",
    "    )\n",
    "\n",
    "    trajectory_generator = preference_comparisons.AgentTrainerWithVideoBuffering(\n",
    "        algorithm=agent,\n",
    "        reward_fn=reward_net,\n",
    "        venv=venv,\n",
    "        rng=rng,\n",
    "        exploration_frac=0.05,\n",
    "        video_folder='videos',\n",
    "        video_length=fragment_length,\n",
    "        name_prefix='rl-video',\n",
    "        timeline=True,\n",
    "    )\n",
    "\n",
    "    default_logger = sb_logger.Logger(folder='/logs', output_formats='stdout,log,csv,tensorboard')\n",
    "    custom_logger = logger.HierarchicalLogger(default_logger=default_logger)\n",
    "\n",
    "    json_fragmenter = preference_comparisons.JsonFragmenter(directory='fragmenter_data')\n",
    "\n",
    "    pref_comparisons = preference_comparisons.PreferenceComparisons(\n",
    "        trajectory_generator,\n",
    "        reward_net,\n",
    "        num_iterations=5,  # Set to 60 for better performance\n",
    "        fragmenter=fragmenter,\n",
    "        preference_gatherer=gatherer,\n",
    "        reward_trainer=reward_trainer,\n",
    "        fragment_length=fragment_length,\n",
    "        transition_oversampling=1,\n",
    "        initial_comparison_frac=0.1,\n",
    "        allow_variable_horizon=False,\n",
    "        initial_epoch_multiplier=4,\n",
    "        query_schedule=\"hyperbolic\",\n",
    "        custom_logger=custom_logger,\n",
    "        json_fragmenter=json_fragmenter,\n",
    "    )\n",
    "\n",
    "    return pref_comparisons.train(\n",
    "        total_timesteps=100_000,\n",
    "        total_comparisons=1000,\n",
    "        tb_log_name=tb_log_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare classical pairwise comparison (baseline) with groupwise comparison (proposed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(f\"Pairwise comparison {i}\")\n",
    "#     intantiate_and_train(True, f\"pairsise_{i}\")\n",
    "\n",
    "for i in range(1):\n",
    "    print(f\"Group comparison {i}\")\n",
    "    intantiate_and_train(False, f\"groupwise_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we trained the reward network using the preference comparisons algorithm, we can wrap our environment with that learned reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.rewards.reward_wrapper import RewardVecEnvWrapper\n",
    "\n",
    "learned_reward_venv = RewardVecEnvWrapper(venv, reward_net.predict_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train an agent that sees only the shaped, learned reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7a1b8839c4c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = PPO(\n",
    "    seed=0,\n",
    "    policy=FeedForward32Policy,\n",
    "    policy_kwargs=dict(\n",
    "        features_extractor_class=NormalizeFeaturesExtractor,\n",
    "        features_extractor_kwargs=dict(normalize_class=RunningNorm),\n",
    "    ),\n",
    "    env=learned_reward_venv,\n",
    "    batch_size=64,\n",
    "    ent_coef=0.01,\n",
    "    n_epochs=10,\n",
    "    n_steps=2048 // learned_reward_venv.num_envs,\n",
    "    clip_range=0.1,\n",
    "    gae_lambda=0.95,\n",
    "    gamma=0.97,\n",
    "    learning_rate=2e-3,\n",
    ")\n",
    "learner.learn(100_000)  # Note: set to 100_000 to train a proficient expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can evaluate it using the original reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -11 +/- 0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "n_eval_episodes = 100\n",
    "reward_mean, reward_std = evaluate_policy(learner.policy, venv, n_eval_episodes)\n",
    "reward_stderr = reward_std / np.sqrt(n_eval_episodes)\n",
    "print(f\"Reward: {reward_mean:.0f} +/- {reward_stderr:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('imitation_ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /imitation/docs/tutorials/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-0.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-0.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-1.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-1.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-2.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-2.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-3.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-3.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-4.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-4.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-5.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-5.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-6.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-6.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-6.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-7.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-7.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-7.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-8.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-8.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-9.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-9.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-9.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-10.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-10.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-10.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-11.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-11.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-11.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-12.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-12.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-12.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-13.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-13.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-13.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-14.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-14.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-14.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-15.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-15.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-15.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-16.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-16.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-16.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-17.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-17.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-17.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-18.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-18.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-18.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-19.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-19.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-19.mp4\n",
      "Moviepy - Building video /imitation/docs/tutorials/videos/training-episode-20.mp4.\n",
      "Moviepy - Writing video /imitation/docs/tutorials/videos/training-episode-20.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /imitation/docs/tutorials/videos/training-episode-20.mp4\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"Reacher-v4\", render_mode='rgb_array')\n",
    "env = RecordVideo(env, './evaluation_videos', name_prefix=\"reacher\", episode_trigger=lambda x: x % 1 == 0) \n",
    "\n",
    "# Run the model in the environment\n",
    "obs, info = env.reset()\n",
    "for _ in range(1000):\n",
    "        action, _states = learner.predict(obs, deterministic=True)\n",
    "        obs, reward, _ ,done, info = env.step(action)\n",
    "        if done:\n",
    "            obs, info = env.reset()\n",
    "            \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "439158cd89905785fcc749928062ade7bfccc3f087fab145e5671f895c635937"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
